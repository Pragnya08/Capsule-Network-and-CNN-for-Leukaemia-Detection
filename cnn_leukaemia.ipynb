{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pragnya08/Capsule-Network-and-CNN-for-Leukaemia-Detection/blob/main/cnn_leukaemia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm.auto import tqdm\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "import random as rn\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import custom_object_scope"
      ],
      "metadata": {
        "id": "VOFx0g1z5CXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cn35XjkdDr0"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!kaggle datasets download -d andrewmvd/leukemia-classification\n",
        "!unzip leukemia-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY3fsiFAdJbt"
      },
      "outputs": [],
      "source": [
        "# Set the base directory of your dataset\n",
        "base_path = 'C-NMC_Leukemia'  # Adjust this to the path where your dataset is located\n",
        "\n",
        "# Folds and categories\n",
        "folds = ['fold_0', 'fold_1', 'fold_2']\n",
        "categories = ['all', 'hem']\n",
        "\n",
        "# Path to store combined training data\n",
        "combined_train_path = os.path.join(base_path, 'combined_training_data')\n",
        "if not os.path.exists(combined_train_path):\n",
        "    os.mkdir(combined_train_path)\n",
        "    for category in categories:\n",
        "        os.mkdir(os.path.join(combined_train_path, category))\n",
        "\n",
        "# Combine images from all folds into one directory for each category\n",
        "for fold in folds:\n",
        "    for category in categories:\n",
        "        source_path = os.path.join(base_path, 'training_data', fold, category)\n",
        "        target_path = os.path.join(combined_train_path, category)\n",
        "        if os.path.exists(source_path):\n",
        "            for file in os.listdir(source_path):\n",
        "                if file.endswith('.bmp'):\n",
        "                    shutil.copy(os.path.join(source_path, file), target_path)\n",
        "\n",
        "# Function to count images in a directory\n",
        "def count_images_in_directory(directory_path):\n",
        "    return len([file for file in os.listdir(directory_path) if file.endswith('.bmp')])\n",
        "\n",
        "# Count images in combined training data\n",
        "image_counts = {category: count_images_in_directory(os.path.join(combined_train_path, category)) for category in categories}\n",
        "print(\"Total number of cancer cell images (all):\", image_counts['all'])\n",
        "print(\"Total number of normal cell images (hem):\", image_counts['hem'])\n",
        "\n",
        "\n",
        "print(\"Total number of images in training:\", sum(image_counts.values()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHSoITtwejC0"
      },
      "outputs": [],
      "source": [
        "# Path to the combined training data\n",
        "combined_train_path = os.path.join(base_path, 'combined_training_data')\n",
        "\n",
        "# Categories\n",
        "categories = ['all', 'hem']\n",
        "\n",
        "# Split data\n",
        "def split_data(category, train_split=0.70, val_split=0.20, test_split=0.10):\n",
        "    files = [file for file in os.listdir(os.path.join(combined_train_path, category)) if file.endswith('.bmp')]\n",
        "    train_val, test = train_test_split(files, test_size=test_split, random_state=42)\n",
        "    train, val = train_test_split(train_val, test_size=val_split/(train_split+val_split), random_state=42)\n",
        "    return train, val, test\n",
        "\n",
        "# Prepare directories for split datasets\n",
        "for subset in ['train', 'validation', 'test']:\n",
        "    subset_path = os.path.join(base_path, subset)\n",
        "    if not os.path.exists(subset_path):\n",
        "        os.mkdir(subset_path)\n",
        "    for category in categories:\n",
        "        category_path = os.path.join(subset_path, category)\n",
        "        if not os.path.exists(category_path):\n",
        "            os.mkdir(category_path)\n",
        "\n",
        "# Split and distribute files\n",
        "for category in categories:\n",
        "    train, val, test = split_data(category)\n",
        "    for file, subset in zip([train, val, test], ['train', 'validation', 'test']):\n",
        "        for img in file:\n",
        "            shutil.copy(os.path.join(combined_train_path, category, img),\n",
        "                        os.path.join(base_path, subset, category))\n",
        "\n",
        "# Count and print the number of images in each subset\n",
        "for subset in ['train', 'validation', 'test']:\n",
        "    print(f\"{subset.capitalize()} Set:\")\n",
        "    for category in categories:\n",
        "        count = len(os.listdir(os.path.join(base_path, subset, category)))\n",
        "        print(f\"  {category} count: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdN64u75kXpO"
      },
      "outputs": [],
      "source": [
        "def count_images_in_directory(directory_path):\n",
        "    \"\"\"\n",
        "    Counts the number of .bmp files in a given directory and its subdirectories.\n",
        "    \"\"\"\n",
        "    total_count = 0\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.bmp'):\n",
        "                total_count += 1\n",
        "    return total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04oTrKHcl315"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Paths\n",
        "train_all_path = '/content/C-NMC_Leukemia/train/all'\n",
        "train_hem_path = '/content/C-NMC_Leukemia/train/hem'\n",
        "training_path = '/content/C-NMC_Leukemia/train'\n",
        "validation_all_path = '/content/C-NMC_Leukemia/validation/all'\n",
        "validation_hem_path = '/content/C-NMC_Leukemia/validation/hem'\n",
        "validation_path = '/content/C-NMC_Leukemia/validation'\n",
        "test_path = '/content/C-NMC_Leukemia/test'\n",
        "training_count = count_images_in_directory(training_path)\n",
        "print(f\"Number of images in training path: {training_count}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jma7HDSCombC"
      },
      "outputs": [],
      "source": [
        "# Count images in each class\n",
        "train_all_count = count_images_in_directory(train_all_path)\n",
        "train_hem_count = count_images_in_directory(train_hem_path)\n",
        "\n",
        "# Print the counts\n",
        "print(f\"Training 'all' count: {train_all_count}\")\n",
        "print(f\"Training 'hem' count: {train_hem_count}\")\n",
        "\n",
        "# Visualize the data for training data\n",
        "labels = ['all', 'hem']\n",
        "counts = [train_all_count, train_hem_count]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, counts, color=['blue', 'orange'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.title('Class Distribution in Training Data')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9WRXDSq0LpW"
      },
      "outputs": [],
      "source": [
        "def get_image_paths(directory_path):\n",
        "    \"\"\"\n",
        "    Returns a list of file paths for .bmp files in a given directory.\n",
        "    \"\"\"\n",
        "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith('.bmp')]\n",
        "\n",
        "\n",
        "# Load image paths\n",
        "train_all_images = get_image_paths(train_all_path)\n",
        "train_hem_images = get_image_paths(train_hem_path)\n",
        "\n",
        "# Calculate total and expected number of images\n",
        "num_training_samples = len(train_all_images) + len(train_hem_images)\n",
        "\n",
        "expected_samples_per_class = training_count // 2\n",
        "\n",
        "# Output expected counts\n",
        "print(\"Number of expected images per class:\", expected_samples_per_class)\n",
        "\n",
        "# Handle sub-sampling for the 'all' class\n",
        "sampled_all = random.sample(train_all_images, min(len(train_all_images), expected_samples_per_class))\n",
        "print(\"Number of sampled cancer cell images:\", len(sampled_all))\n",
        "\n",
        "# Calculate need and perform augmentation if necessary for 'hem' class\n",
        "hem_samples_needed = max(0, expected_samples_per_class - len(train_hem_images))\n",
        "if hem_samples_needed > 0 and len(train_hem_images) > 0:\n",
        "    sampled_hem = random.sample(train_hem_images, hem_samples_needed)\n",
        "    print(\"Number of sampled normal cell images to perform augmentation:\", len(sampled_hem))\n",
        "else:\n",
        "    print(\"No augmentation needed for 'hem' class.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VctVqQ8I7X4x"
      },
      "outputs": [],
      "source": [
        "def compute_gradient(image):\n",
        "    '''\n",
        "    Compute the gradient of the image\n",
        "    :param image: the image for which to compute the gradient\n",
        "    :return: gradient magnitude image\n",
        "    '''\n",
        "    image_tensor = tf.convert_to_tensor(image, dtype=tf.float32)\n",
        "    # Expanding image dimensions from HxWxC to 1xHxWxC for batch processing\n",
        "    image_tensor = tf.expand_dims(image_tensor, axis=0)\n",
        "    # Using Sobel operator to compute gradients\n",
        "    gx = tf.image.sobel_edges(image_tensor)[:,:,:,0,0]\n",
        "    gy = tf.image.sobel_edges(image_tensor)[:,:,:,0,1]\n",
        "    # Compute gradient magnitude\n",
        "    grad_mag = tf.sqrt(tf.square(gx) + tf.square(gy))\n",
        "    return np.squeeze(grad_mag.numpy(), axis=0)  # Remove batch dimension\n",
        "\n",
        "def plot_heatmap(gradient, title=\"Gradient Magnitude Heatmap\"):\n",
        "    '''\n",
        "    Plot the heatmap\n",
        "    :param gradient: gradient magnitude image\n",
        "    :param title: title of the plot\n",
        "    '''\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(gradient, cmap='hot', interpolation='nearest')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Example image path (adjust the path as needed)\n",
        "example_image_path = '/content/C-NMC_Leukemia/train/hem/UID_H10_100_1_hem.bmp'\n",
        "original_image = cv2.imread(example_image_path)\n",
        "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Compute gradient and plot heatmap\n",
        "gradient_image = compute_gradient(original_image)\n",
        "plot_heatmap(gradient_image)\n",
        "\n",
        "def save_heatmap(gradient, file_path):\n",
        "    '''\n",
        "    Save the heatmap to a file\n",
        "    :param gradient: gradient magnitude image\n",
        "    :param file_path: path to save the heatmap\n",
        "    '''\n",
        "    plt.imshow(gradient, cmap='hot')\n",
        "    plt.colorbar()\n",
        "    plt.axis('off')\n",
        "    # Save as PNG format\n",
        "    plt.savefig(file_path, format='png')\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtLb7HTT6nUx"
      },
      "outputs": [],
      "source": [
        "def random_flip_or_rotation(original_image):\n",
        "    '''\n",
        "    Randomly rotates or flips the image\n",
        "    :param original_image: the image on which to perform the transformation\n",
        "    :return: the transformed image\n",
        "    '''\n",
        "    if random.randint(0, 1):\n",
        "        if random.randint(0, 1):\n",
        "            new_image = tf.image.flip_left_right(original_image)\n",
        "        else:\n",
        "            new_image = tf.image.flip_up_down(original_image)\n",
        "    else:\n",
        "        k = random.randint(1, 3)\n",
        "        new_image = tf.image.rot90(original_image, k)\n",
        "    return np.asarray(new_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ke__VbnU6p3J"
      },
      "outputs": [],
      "source": [
        "# Example image path (adjust the path as needed)\n",
        "example_image_path = '/content/C-NMC_Leukemia/train/hem/UID_H10_100_1_hem.bmp'\n",
        "original_image = cv2.imread(example_image_path)\n",
        "\n",
        "vertical_flip = tf.image.flip_up_down(original_image)\n",
        "horizontal_flip = tf.image.flip_left_right(original_image)\n",
        "rotation_90 = tf.image.rot90(original_image, k=1)\n",
        "rotation_180 = tf.image.rot90(original_image, k=2)\n",
        "rotation_270 = tf.image.rot90(original_image, k=3)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "fig.add_subplot(2, 3, 1)\n",
        "plt.imshow(original_image)\n",
        "plt.axis('off')\n",
        "plt.title(\"Original\")\n",
        "\n",
        "fig.add_subplot(2, 3, 2)\n",
        "plt.imshow(vertical_flip)\n",
        "plt.axis('off')\n",
        "plt.title(\"Flipped Vertically\")\n",
        "\n",
        "fig.add_subplot(2, 3, 3)\n",
        "plt.imshow(horizontal_flip)\n",
        "plt.axis('off')\n",
        "plt.title(\"Flipped Horizontally\")\n",
        "\n",
        "fig.add_subplot(2, 3, 4)\n",
        "plt.imshow(rotation_90)\n",
        "plt.axis('off')\n",
        "plt.title(\"Rotated by 90°\")\n",
        "\n",
        "fig.add_subplot(2, 3, 5)\n",
        "plt.imshow(rotation_180)\n",
        "plt.axis('off')\n",
        "plt.title(\"Rotated by 180°\")\n",
        "\n",
        "fig.add_subplot(2, 3, 6)\n",
        "plt.imshow(rotation_270)\n",
        "plt.axis('off')\n",
        "plt.title(\"Rotated by 270°\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6f8RgKn6yIp"
      },
      "outputs": [],
      "source": [
        "def crop_and_resize_image(image):\n",
        "    '''\n",
        "    Crops the image with a thresholding technique and resizes it to remove black borders.\n",
        "    :param image: image to crop\n",
        "    :return: cropped and resized image\n",
        "    '''\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)  # Apply threshold\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = contours[0]\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    cropped_image = image[y:y+h, x:x+w]\n",
        "\n",
        "    # Enlarge the image to get a square shape\n",
        "    max_dimension = max(cropped_image.shape)\n",
        "    vertical_gap = max_dimension - cropped_image.shape[0]\n",
        "    top = bottom = vertical_gap // 2 if vertical_gap % 2 == 0 else vertical_gap // 2 + 1\n",
        "    horizontal_gap = max_dimension - cropped_image.shape[1]\n",
        "    left = right = horizontal_gap // 2 if horizontal_gap % 2 == 0 else horizontal_gap // 2 + 1\n",
        "\n",
        "    return cv2.copyMakeBorder(cropped_image, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)  # Padding with black\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEyo4gdw62bg"
      },
      "outputs": [],
      "source": [
        "# Example image path (adjust the path as needed)\n",
        "example_image_path = '/content/C-NMC_Leukemia/train/hem/UID_H10_100_1_hem.bmp'\n",
        "img = cv2.imread(example_image_path)\n",
        "cropped_image = crop_and_resize_image(img)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title(\"Original Image\")\n",
        "\n",
        "fig.add_subplot(1, 2, 2)\n",
        "plt.imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.title(\"Cropped Image\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dArAnTo364WA"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "new_dataset_path = \"/content/SplittedDataset\"\n",
        "training_path_new = new_dataset_path + \"/training_set\"\n",
        "validation_path_new = new_dataset_path + \"/validation_set\"\n",
        "test_path_new = new_dataset_path + \"/test_set\"\n",
        "\n",
        "shutil.rmtree(new_dataset_path, ignore_errors=True)\n",
        "\n",
        "# Create the structure\n",
        "os.makedirs(training_path_new + \"/all\")\n",
        "os.makedirs(training_path_new + \"/hem\")\n",
        "os.makedirs(validation_path_new+ \"/all\")\n",
        "os.makedirs(validation_path_new + \"/hem\")\n",
        "os.makedirs(test_path_new + \"/all\")\n",
        "os.makedirs(test_path_new +  \"/hem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKQjaCn-70UD"
      },
      "outputs": [],
      "source": [
        "sampled_all = [os.path.basename(path) for path in sampled_all]  # Example placeholder\n",
        "hem_samples = [os.path.basename(path) for path in train_hem_images]  # Example placeholder\n",
        "sampled_hem = [os.path.basename(path) for path in sampled_hem]  # Example placeholder\n",
        "validation_set = []  # Example placeholder for validation samples\n",
        "test_set = []  # Example placeholder for test samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WErk3pXqBC0E"
      },
      "outputs": [],
      "source": [
        "for sample in sampled_all:  # Store cropped cancer cell images\n",
        "    img = cv2.imread(training_path + '/all/' + sample)\n",
        "    cropped_image = crop_and_resize_image(img)\n",
        "    cv2.imwrite(training_path_new + '/all/' + sample, cropped_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqNgOrhw8WIK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Loop for normal cell images\n",
        "for sample in hem_samples:\n",
        "    img = cv2.imread(training_path + '/hem/' + sample)\n",
        "    cropped_image = crop_and_resize_image(img)\n",
        "    cv2.imwrite(training_path_new + '/hem/' + sample, cropped_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLs2NI1sA3xr"
      },
      "outputs": [],
      "source": [
        "# Loop for augmented normal cell images\n",
        "for sample in sampled_hem:\n",
        "    img = cv2.imread(training_path + \"/hem/\" + sample)\n",
        "    augmented_img = random_flip_or_rotation(img)\n",
        "    cropped_image = crop_and_resize_image(augmented_img)\n",
        "    cv2.imwrite(training_path_new + '/hem_augmented/' + sample, cropped_image)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zobAu0lyB5yR"
      },
      "outputs": [],
      "source": [
        "validation_set = []\n",
        "# Function to populate validation_set with filenames from the directory\n",
        "def populate_validation_set(directory):\n",
        "    validation_set = []\n",
        "    for label in ['all', 'hem']:\n",
        "        dir_path = os.path.join(directory, label)\n",
        "        if not os.path.exists(dir_path):\n",
        "            print(f\"Directory does not exist: {dir_path}\")\n",
        "            continue\n",
        "        for filename in os.listdir(dir_path):\n",
        "            if filename.endswith(\".bmp\"):\n",
        "                validation_set.append(os.path.join(label, filename))\n",
        "    return validation_set\n",
        "\n",
        "# Populate validation_set\n",
        "validation_set = populate_validation_set(validation_path)\n",
        "\n",
        "# Debugging: Print validation_set contents\n",
        "print(\"Validation set samples:\", validation_set)\n",
        "\n",
        "# Ensure the new directories exist\n",
        "os.makedirs(os.path.join(validation_path_new, \"all\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(validation_path_new, \"hem\"), exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osLf8j5nCgte"
      },
      "outputs": [],
      "source": [
        "count_all = 0\n",
        "count_hem = 0\n",
        "\n",
        "# Processing validation_set images\n",
        "for sample in validation_set:  # Store cropped validation set images\n",
        "    label, filename = sample.split('/')\n",
        "    img_path = os.path.join(validation_path, label, filename)\n",
        "    print(f\"Processing image: {img_path}\")\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"Error reading image: {img_path}\")\n",
        "        continue\n",
        "    cropped_image = crop_and_resize_image(img)\n",
        "    save_path = os.path.join(validation_path_new, label, filename)\n",
        "    print(f\"Saving cropped image to: {save_path}\")\n",
        "    cv2.imwrite(save_path, cropped_image)\n",
        "\n",
        "# Debugging: Verify saved images\n",
        "print(\"Contents of the new validation directory (all):\")\n",
        "all_files = os.listdir(os.path.join(validation_path_new, \"all\"))\n",
        "print(all_files)\n",
        "\n",
        "print(\"Contents of the new validation directory (hem):\")\n",
        "hem_files = os.listdir(os.path.join(validation_path_new, \"hem\"))\n",
        "print(hem_files)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiYNExOHTTO0"
      },
      "outputs": [],
      "source": [
        "count_all = 0\n",
        "count_hem = 0\n",
        "\n",
        "for root, dirs, files in os.walk(test_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.bmp'):  # Ensures only BMP images are processed\n",
        "            img_path = os.path.join(root, file)\n",
        "            print(f\"Processing image: {img_path}\")\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is not None:\n",
        "                cropped_image = crop_and_resize_image(img)  # Ensure this function is defined elsewhere in your script\n",
        "                label = 'all' if 'all' in root else 'hem'\n",
        "                if label == 'all':\n",
        "                    count_all += 1\n",
        "                else:\n",
        "                    count_hem += 1\n",
        "                save_path = os.path.join(test_path_new, label, file)\n",
        "                os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "                cv2.imwrite(save_path, cropped_image)\n",
        "                print(f\"Cropped image saved to: {save_path}\")\n",
        "            else:\n",
        "                print(f\"Image {img_path} not found or could not be read.\")\n",
        "\n",
        "print(f\"Total 'all' images processed: {count_all}\")\n",
        "print(f\"Total 'hem' images processed: {count_hem}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufuoetf0YSbv"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05HIk0D8YRr2"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/SplittedDataset\"\n",
        "TRAINING_PATH = DATASET_PATH + '/training_set'\n",
        "TRAINING_ALL_PATH = TRAINING_PATH + '/all'\n",
        "TRAINING_HEM_PATH = TRAINING_PATH + '/hem'\n",
        "VALIDATION_PATH = DATASET_PATH + '/validation_set'\n",
        "TEST_PATH = DATASET_PATH + '/test_set'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdXiofx_YZ_m"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32  # Reduced batch size\n",
        "IMAGE_HEIGHT = 224  # Reduced image height\n",
        "IMAGE_WIDTH = 224  # Reduced image width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcMNzjW3ZA24"
      },
      "outputs": [],
      "source": [
        "def set_seed ():\n",
        "  '''\n",
        "  set_seed is used to obtain reproducible results using keras during the development phase\n",
        "  '''\n",
        "  seed = 46\n",
        "  # The below is necessary for reproducible results of certain Python hash-based operations.\n",
        "  os.environ[\"PYTHONHASHSEED\"]=\"0\"\n",
        "  # The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
        "  np.random.seed(seed)\n",
        "  # The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
        "  rn.seed(seed)\n",
        "  # The below tf.random.set_seed will make random number generation in TensorFlow have a well-defined initial state.\n",
        "  tf.random.set_seed(seed)\n",
        "\n",
        "\n",
        "def show_training_and_validation_performance(history):\n",
        "  '''\n",
        "  show_training_and_validation_performance is used to plot the performances during the training phase\n",
        "  :param history: object in which are recorded all the events\n",
        "  '''\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(len(acc))\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def load_training_set (image_height, image_width, batch_size):\n",
        "  '''\n",
        "  load_training_set loads the training set from the \"training_set\" folder. The images are resized to height x width\n",
        "  :param image_height: standard height of the images\n",
        "  :param image_width: standard width of the images\n",
        "  :param batch_size: size of each batch\n",
        "  :return: the training set\n",
        "  '''\n",
        "  return image_dataset_from_directory(\n",
        "    TRAINING_PATH,\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = batch_size,\n",
        "    class_names = ['hem', 'all'])\n",
        "def load_validation_set (image_height, image_width, batch_size):\n",
        "  '''\n",
        "  load_validation_set loads the validation set from the \"validation_set\" folder. The images are resized to height x width\n",
        "  :param image_height: standard height of the images\n",
        "  :param image_width: standard width of the images\n",
        "  :param batch_size: size of each batch\n",
        "  :return: the validation set\n",
        "  '''\n",
        "  return image_dataset_from_directory(\n",
        "    VALIDATION_PATH,\n",
        "    image_size = (image_height, image_width),\n",
        "    batch_size = batch_size,\n",
        "    class_names = ['hem', 'all'])\n",
        "\n",
        "def load_test_set(image_height, image_width, batch_size):\n",
        "    '''\n",
        "    load_test_set loads the test set from the \"test_set\" folder. The images are resized to height x width\n",
        "    :param image_height: standard height of the images\n",
        "    :param image_width: standard width of the images\n",
        "    :param batch_size: size of each batch\n",
        "    :return: the test set\n",
        "    '''\n",
        "    test_dataset = image_dataset_from_directory(\n",
        "        TEST_PATH,\n",
        "        label_mode='binary',\n",
        "        image_size=(image_height, image_width),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        class_names=['hem', 'all'])\n",
        "    return test_dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compile_model (model, optimizer='adamax', learning_rate = 0.001):\n",
        "  '''\n",
        "  compile_model is used to compile the current model\n",
        "  :param model: model to compile\n",
        "  :param optimizer: optimizer to be used\n",
        "  :param learning_rate: learning rate parameter for the optimizer\n",
        "  '''\n",
        "  if optimizer == 'adamax':\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "      optimizer=optimizers.Adamax(learning_rate=learning_rate),\n",
        "      metrics=[\"accuracy\"])\n",
        "  elif optimizer == 'rmsprop':\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                  optimizer = optimizers.RMSprop(learning_rate=learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "def run_model(model, epochs=20, patience=5, monitor='val_loss'):\n",
        "    '''\n",
        "    run_model is used to run the current model without saving it\n",
        "    :param model: model to run\n",
        "    :param epochs: how many epochs to do\n",
        "    :param patience: patience value for Early Stopping\n",
        "    :param monitor: what to monitor for Early Stopping\n",
        "    '''\n",
        "    callbacks_list = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience)\n",
        "    ]\n",
        "    history = model.fit(train_dataset,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=validation_dataset,\n",
        "                        callbacks=callbacks_list)\n",
        "    show_training_and_validation_performance(history)\n",
        "\n",
        "\n",
        "def evaluate_model (model):\n",
        "  '''\n",
        "  evaluate_model is used to plot some statistics about the performance on the test set\n",
        "  :param model: model to consider\n",
        "  '''\n",
        "  y_score = model.predict(test_dataset)\n",
        "  y_pred = np.rint(y_score)\n",
        "  y_true = tf.concat([labels_batch for data_batch, labels_batch in test_dataset], axis = 0)\n",
        "  print(\"Classification report: \")\n",
        "  print(metrics.classification_report(y_true,y_pred,digits = 4))\n",
        "  metrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
        "\n",
        "  # ROC curve\n",
        "  fpr,tpr,th = metrics.roc_curve(y_true,y_score)\n",
        "  roc_auc = metrics.roc_auc_score(y_true,y_score)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "  plt.plot([0, 1], [0, 1], linestyle='--', color='navy')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('ROC curve')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhXTgXEFZTas"
      },
      "outputs": [],
      "source": [
        "\n",
        "shapes = {}\n",
        "\n",
        "total_entries = []\n",
        "entries = os.listdir(TRAINING_ALL_PATH)\n",
        "total_entries += entries\n",
        "for entry in tqdm(entries):\n",
        "  img = cv2.imread(TRAINING_ALL_PATH + '/' + entry)\n",
        "  if img.shape <= (300, 300):\n",
        "    shapes[(300,300)] = shapes.get((300,300), 0) + 1\n",
        "  if img.shape <= (299, 299):\n",
        "    shapes[(299,299)] = shapes.get((299,299), 0) + 1\n",
        "  if img.shape <= (224, 224):\n",
        "    shapes[(224,224)] = shapes.get((224,224), 0) + 1\n",
        "entries = os.listdir(TRAINING_HEM_PATH)\n",
        "total_entries += entries\n",
        "for entry in tqdm(entries):\n",
        "  img = cv2.imread(TRAINING_HEM_PATH + '/' + entry)\n",
        "  if img.shape <= (300, 300):\n",
        "    shapes[(300,300)] = shapes.get((300,300), 0) + 1\n",
        "  if img.shape <= (299, 299):\n",
        "    shapes[(299,299)] = shapes.get((299,299), 0) + 1\n",
        "  if img.shape <= (224, 224):\n",
        "    shapes[(224,224)] = shapes.get((224,224), 0) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyWpht_wZhqd"
      },
      "outputs": [],
      "source": [
        "print(\"Number of training images: \", len(total_entries))\n",
        "print(\"Common shapes: \", shapes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWwqLxZ1Zm7H"
      },
      "outputs": [],
      "source": [
        "\n",
        "set_seed()\n",
        "\n",
        "train_dataset = load_training_set(IMAGE_HEIGHT, IMAGE_WIDTH, BATCH_SIZE) # with default values\n",
        "validation_dataset = load_validation_set(IMAGE_HEIGHT, IMAGE_WIDTH, BATCH_SIZE) # with default values\n",
        "test_dataset = load_test_set(IMAGE_HEIGHT, IMAGE_WIDTH, BATCH_SIZE) # with default values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IAa2W3Qzohd"
      },
      "source": [
        "### one dense layer with 256 neurons and one dropouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9mtO7_obYji"
      },
      "outputs": [],
      "source": [
        "\n",
        "np.random.seed(24)\n",
        "\n",
        "inputs = keras.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(filters=32, padding='same', kernel_size=(3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "x = layers.Conv2D(filters=64, padding='same', kernel_size=(3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "x = layers.Conv2D(filters=128, padding='same', kernel_size=(3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(3,3))(x)\n",
        "x = layers.Conv2D(filters=256, padding='same', kernel_size=(3,3), activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=(5,5))(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256, activation='relu') (x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "compile_model(model)\n",
        "plot_model(model, to_file='cnn_architecture.png', show_shapes=True, show_layer_names=True, dpi=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIU2a5bFbcJQ"
      },
      "outputs": [],
      "source": [
        "run_model(model, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsfy1ELoDzKa"
      },
      "source": [
        "capusle - 128 change the size when running this\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwBY-qasipRu"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BREd5r_36qZ-"
      },
      "outputs": [],
      "source": [
        "model.save('simplecnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Buy94CLm8FxE"
      },
      "outputs": [],
      "source": [
        "test_dataset = load_test_set(IMAGE_HEIGHT, IMAGE_WIDTH, BATCH_SIZE)\n",
        "scratch_test_dataset = load_test_set(300, 300, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sj_htOko8KP2"
      },
      "outputs": [],
      "source": [
        "num_all_test = len(os.listdir(TEST_PATH + \"/all\"))\n",
        "num_hem_test = len(os.listdir(TEST_PATH + \"/hem\"))\n",
        "\n",
        "total_test = num_all_test + num_hem_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JxCMzYX8Mo7"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('total test cancer cell images:', num_all_test)\n",
        "print('total test normal cell images:', num_hem_test)\n",
        "print(\"--\")\n",
        "print(\"Total test images:\", total_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIFhOPg24lZH"
      },
      "outputs": [],
      "source": [
        "\n",
        "cnn_model = load_model('/content/simplecnn.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6KUMVQvFQwE"
      },
      "outputs": [],
      "source": [
        "def evaluate_classifier(model, dataset):\n",
        "    misclassified_indices = []\n",
        "    correctly_classified_indices = []\n",
        "    index = 0\n",
        "    for images, labels in dataset:  # Assuming dataset is batched\n",
        "        preds = model.predict(images)\n",
        "        pred_labels = (preds.flatten() > 0.5).astype(int)\n",
        "        true_labels = labels.numpy().astype(int)\n",
        "        for i in range(len(pred_labels)):\n",
        "            if pred_labels[i] == true_labels[i]:\n",
        "                correctly_classified_indices.append(index)\n",
        "            else:\n",
        "                misclassified_indices.append(index)\n",
        "            index += 1\n",
        "    return correctly_classified_indices, misclassified_indices\n",
        "\n",
        "\n",
        "def plot_images_by_indices(dataset, indices, title, labels_dict, max_images_per_figure=50):\n",
        "    images_collected = []\n",
        "    labels_collected = []\n",
        "    for idx, (images, labels) in enumerate(dataset.unbatch()):\n",
        "        if idx in indices:\n",
        "            images_collected.append(images.numpy())\n",
        "            labels_collected.append(int(labels.numpy()[0]))  # Ensure single element conversion\n",
        "            if len(images_collected) == len(indices):\n",
        "                break\n",
        "\n",
        "    total_images = len(images_collected)\n",
        "    for i in range(0, total_images, max_images_per_figure):\n",
        "        end_index = min(i + max_images_per_figure, total_images)\n",
        "        num_images = end_index - i\n",
        "        cols = 5\n",
        "        rows = (num_images + cols - 1) // cols\n",
        "        plt.figure(figsize=(cols * 4, rows * 4))\n",
        "        for j in range(num_images):\n",
        "            ax = plt.subplot(rows, cols, j + 1)\n",
        "            image_index = i + j\n",
        "            ax.imshow(images_collected[image_index].astype('uint8'))\n",
        "            ax.set_title(f\"{title}\\nIndex: {indices[image_index]}\\nLabel: {labels_dict[labels_collected[image_index]]}\", fontsize=10)\n",
        "            ax.axis('off')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "correct_cnn, incorrect_cnn = evaluate_classifier(cnn_model, test_dataset)\n",
        "\n",
        "# Dictionary for label conversion\n",
        "labels_dict = {0: 'hem', 1: 'all'}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oe2CeBp727Co"
      },
      "outputs": [],
      "source": [
        "plot_images_by_indices(test_dataset, incorrect_cnn, \"Incorrectly Classified by CNN\", labels_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6bGVyEW28Uj"
      },
      "outputs": [],
      "source": [
        "plot_images_by_indices(test_dataset, correct_cnn, \"Correctly Classified by CNN\", labels_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}